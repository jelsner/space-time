---
title: "Space-time animation"
author: "Elsner"
output:
  html_document:
editor_options: 
  chunk_output_type: console
---

# Climate animation of daily high temperature

From: https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/

## Packages
```{r}
library(raster)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(rgdal) # before library(sf)
library(sf)
library(rnaturalearth)
library(extrafont)
library(showtext)
library(RColorBrewer)
library(gifski)
library(ncdf4)
library(here)
```

## Preparation

### Data

First, we need to download the STEAD dataset of the maximum temperature (`tmax_pen.nc`) in netCDF format from the CSIC repository here (the size of the data is 2 GB). It is a set of data with a spatial resolution of 5 km and includes daily maximum temperatures from 1901 to 2014. 

In climatology and meteorology, a widely used format is that of netCDF databases, which allow to obtain a multidimensional structure and to exchange data independently of the usued operating system. It is a space-time format with a regular or irregular grid. The multidimensional structure in the form of arrays or cubes can handle not only spatio-temporal data but also multivariate ones. In our dataset we will have an array of three dimensions: longitude, latitude and time of the maximum temperature.

### Import the data

The netCDF format with `.nc` extension can be imported with `brick()` from the {raster} package. In our data we only have one variable, therefore it would not be necessary to use the `varname =` argument.
```{r}
tmx <- brick("tmax_pen.nc", varname = "tx")
tmx
```

To access any layer we use [[ ]] with the corresponding index. So we can easily plot any day of the 41,638 days we have.
```{r}
plot(tmx[[200]], col = rev(heat.colors(7)))

library(tmap)
tm_shape(tmx[[200]]) +
  tm_raster() 
```

## Calculate the average temperature

In this step the objective is to calculate the average maximum temperature for each day of the year. Therefore, the first thing we do is to create a vector, indicating the day of the year for the entire time series. We do this with the `yday()` function from the {lubridate} package.
```{r}
time_days <- yday(seq(as_date("1901-01-01"), as_date("2014-12-31"), "day"))
```

From the {raster} package we have the `stackApply()` function that allows us to apply another function on groups of layers, or rather, indexes. Since our dataset is large, we include this function in parallelization functions.

For the parallelization we start and end always with the `beginCluster()` and `endCluster()`. In the first function we must indicate the number of cores we want to use. In this case, I use 4 of 7 possible cores, however, the number must be changed according to the characteristics of each CPU, the general rule is n-1. So the `clusterR()` function execute a function in parallel with multiple cores. The first argument corresponds to the raster object, the second to the used function, and as list argument we pass the arguments of the `stackApply()` function: the indexes that create the groups and the function used for each of the groups. Adding the argument progress = 'text' shows a progress bar of the calculation process.
```{r}
beginCluster(4)
tmx_mean <- clusterR(tmx, stackApply, args = list(indices = time_days, fun = mean))
endCluster()
```

This took about 20 minutes.

```{r}
tm_shape(tmx_mean[[36]]) +
  tm_raster() 
```

Write the raster to a file.
```{r}
writeRaster(tmx_mean, file = "DailyMaxTemp.nc")

tmx_mean <- brick("DailyMaxTemp.nc")
```

## Smooth the temperature variability

Before we start to smooth the time series of our RasterBrick, an example of why we do it. We extract a pixel from our dataset at coordinates -1ยบ of longitude and 40ยบ of latitude using the `extract()` function. Since the function with the same name appears in several packages, we must change to the form `package_name::function_name`. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. The next step is to create a data frame with a dummy date and the extracted maximum temperature.

```{r}
point_ts <- raster::extract(tmx_mean, matrix(c(-1, 40), nrow = 1))
dim(point_ts)
```
```{r}
df <- data.frame(date = seq(as_date("2000-01-01"), as_date("2000-12-31"), "day"),
                 tmx = point_ts[1,])
```

Visualize the maximum temperature
```{r}
ggplot(data = df, 
       mapping = aes(date, tmx)) + 
  geom_line() + 
  scale_x_date(date_breaks = "month", date_labels = "%b") +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  labs(y = "maximum temperature", x = "", colour =  "") +
  theme_minimal()
```

Another smoother. https://stats.stackexchange.com/questions/68403/smooth-a-circular-periodic-time-series

As a script.
```{r}
y <- c(df$tmx, df$tmx, df$tmx)
x.mid <- 1:366 
offset <- 366
y.smooth <- lowess(y, f = 1/32)
df$est2 <- y.smooth$y[x.mid + offset]
```

As a function.
```{r}
daily_smooth <- function(x, f = 1/32){
  
  if(all(is.na(x))){
   
    return(x) 
   
  } else {
  y <- c(x, x, x)
  x.mid <- 1:366
  y.smooth <- lowess(y, f = f)
  est <- y.smooth$y[x.mid + offset]

  return(est)
  
  }
}

df$est2 <- daily_smooth(df$tmx)
```

Plot together
```{r}
dfL <- df %>% 
       pivot_longer(c(2, 4, 5), names_to = "var", values_to = "temp")

ggplot(dfL, 
       aes(date, temp, 
           colour = var)) + 
     geom_line() + 
  scale_x_date(date_breaks = "month", date_labels = "%b") +
  scale_y_continuous(breaks = seq(5, 28, 2)) +
  scale_colour_manual(values = c("orange", "red", "black")) +
  labs(y = "maximum temperature", x = "", colour =  "") +
  theme_minimal()
```

As we see in the graph, the smoothed curve follows the original curve very well. 

In the next step we apply our function to the raster brick with the `calc()` function. The function returns as many layers as those returned by the function used for each of the time series.

```{r}
tmx_smooth <- calc(tmx_mean, fun = daily_smooth)
```

## Visualization

### Preparation

To visualize the maximum temperatures throughout the year, first we convert the raster brick to a data frame, including longitude and latitude and removing all time series with missing values (`NA`).
```{r}
tmx_mat <- as.data.frame(tmx_smooth, xy = TRUE, na.rm = TRUE)
str(tmx_mat[, 1:10])
```

Next rename the columns
```{r}
tmx_mat <- set_names(tmx_mat, c("lon", "lat", str_c("D", 1:366)))
str(tmx_mat[, 1:10])
```

Second, we import the administrative boundaries with the `ne_countries()` function from the {rnaturalearth} package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.

```{r}
map <- ne_countries(scale = 'small', returnclass = "sf") %>%
  st_cast("MULTILINESTRING") %>%
  st_crop(xmin = -10, xmax = 5, ymin = 35, ymax = 44)
```

Third, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.
```{r}
( lab <- as_date(0:365, origin = "2000-01-01") %>% 
  format("%d %B") )
```

Fourth, we apply the `cut()` function with the breaks to all the columns with temperature data of each day of the year.
```{r}
ct <- c(-5, 0, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 40, 45)
tmx_mat_cat <- mutate_at(tmx_mat, 3:368, cut, breaks = ct)
str(tmx_mat_cat[1:10])
```

Fifth we define the color ramp.
```{r}
col_spec <- colorRampPalette(rev(brewer.pal(11, "RdBu")))
```

### Static map

In this first plot we make a map of May 29 (day 150). We use the `aes_string()` function instead of `aes()` to use the column names in string format. With the `geom_raster()` function we add the gridded temperature data as the first layer of the graph and with `geom_sf()` the boundaries in {sf} class. Finally, the `guide_colorsteps()` function allows us to create a nice legend based on the classes created by the `cut()` function.
```{r}
ggplot(tmx_mat_cat) + 
         geom_raster(aes_string("lon", "lat", fill = "D150")) +
         geom_sf(data = map,
                 colour = "grey50", size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = 0.5,
                                 title.position = "right",
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = "top",
      legend.justification = 1,
      plot.caption = element_text(margin = margin(b = 5, t = 10, unit = "pt")),                
      plot.title = element_text(size = 16, face = "bold", 
                                margin = margin(b = 2, t = 5, unit = "pt")),
     plot.subtitle = element_text(size = 13, 
                                  margin = margin(b = 10, t = 5, unit = "pt"))) +
   labs(title = "Average maximum temperature during the year in Spain", 
     subtitle = lab[150], 
     caption = "Reference period 1901-2014. Data: STEAD",
     fill = "ยบC")
```

### Animation

The final animation consists of creating a gif from all the images of 366 days, in principle, the {gganimate} package could be used, but in my experience it is slower, since it requires a data frame in long format. In this example a long table would have more than seven million rows. 

So what we do here is to use a loop over the columns and join all the created images with the {gifski} package.

Before looping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.
```{r}
time_step <- str_c("D", 1:366)
files <- str_c("ta_anim/D", str_pad(1:366, 3, "left", "0"), ".png")
```
Lastly, we include the above plot construction in a for loop. This takes a few minutes to run.
```{r}
for(i in 1:366){

 ggplot(tmx_mat_cat) + 
         geom_raster(aes_string("lon", "lat", fill = time_step[i])) +
         geom_sf(data = map,
                 colour = "grey50", size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = .5,
                                 title.position = "right",
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = "top",
         legend.justification = 1,
         plot.caption = element_text(margin = margin(b = 5, t = 10, unit = "pt")),
         plot.title = element_text(size = 16, face = "bold", 
                                margin = margin(b = 2, t = 5, unit = "pt")),
         plot.subtitle = element_text(size = 13, 
                                  margin = margin(b = 10, t = 5, unit = "pt"))) +
   labs(title = "Average maximum temperature during the year in Spain", 
     subtitle = lab[i], 
     caption = "Reference period 1901-2014. Data: STEAD",
     fill = "ยบC")

  ggsave(files[i], width = 8.28, height = 7.33, type = "cairo")
  
}
```

After having created images for each day of the year, we only have to create the gif.
```{r}
gifski(files, "tmx_spain.gif", 
       width = 800, height = 700, 
       loop = FALSE, 
       delay = 0.05)
```

## PRISM data

Try the above using PRISM data over the U.S. for four consecutive years.

Get daily PRISM data with functions from the {prism} package for a single year. About 20 minutes per year of daily data.
```{r}
library(prism)

options(prism.path = "Data/PRISM/1993")

t0 <- proc.time()
get_prism_dailys(
  type = "tmax", 
  minDate = "1993-01-01", 
  maxDate = "1993-12-31", 
  keepZip = FALSE 
)
proc.time() - t0
```

Create the folder and file names as character strings. Read the rasters for one year and create a stack. About 70 sec to read rasters and create a stack.
```{r}
t0 <- proc.time()

dates <- seq(as_date("1993-01-01"), 
             as_date("1993-12-31"), 
             by = "day")

time_days <- yday(dates)
file_days <- gsub("-", "", dates)
yearC <- as.character(year(dates))

folder_names <- paste0("PRISM_tmax_stable_4kmD2_", 
                       file_days, 
                       "_bil")
file_names <- paste0("PRISM_tmax_stable_4kmD2_", 
                       file_days, 
                       "_bil.bil")

tmax.s <- NULL
for(i in length(file_names):1){
r <- raster(here("Data", 
                 "PRISM", 
                 yearC[i], 
                 folder_names[i], 
                 file_names[i]))
on.exit(close(r))
tmax.s <- stack(r, tmax.s)
# print(dates[i])
}

tmaxDaily1993 <- tmax.s
proc.time() - t0
```

Combine the yearly stacks. 1.5 secs for four years.
```{r}
t0 <- proc.time()
tmaxDaily <- stack(tmaxDaily1990, tmaxDaily1991, tmaxDaily1992, tmaxDaily1993)
nlayers(tmaxDaily)
proc.time() - t0
```

## Calculate the average temperature

Calculate the average maximum temperature for each day of the year. First create a vector indicating the day of the year for the entire time series with the `yday()` function from the {lubridate} package.
```{r}
time_days <- yday(seq(as_date("1990-01-01"), as_date("1993-12-31"), "day"))
```

From the {raster} package we have the `stackApply()` function that allows us to apply another function on groups of layers, or rather, indexes. Since our dataset is large, we include this function in parallelization functions.

For the parallelization we start and end always with the `beginCluster()` and `endCluster()`. In the first function we must indicate the number of cores we want to use. In this case, we use 4 cores.

The `clusterR()` function executes a function in parallel. The first argument corresponds to the raster object, the second is the  function, and as list argument we pass the arguments of the `stackApply()` function: the indexes that create the groups and the function used for each of the groups. Adding the argument progress = 'text' shows a progress bar of the calculation process.
```{r}
t0 <- proc.time()

beginCluster()
tmaxDailyAvg <- clusterR(tmaxDaily, 
                         fun = stackApply, 
                         args = list(indices = time_days, fun = mean),
                         progress = 'text')
endCluster()

proc.time() - t0
```

This took about 19 hr.

Area of continental US: 8.1e6 km^2
Area of Spain: .5e6 km2

Write the raster to a file.
```{r}
writeRaster(tmaxDailyAvg, 
            file = "tmaxDailyAvg.nc")
```

## Map the temperatures over the southeast

Map the average high temperature for the first 6 days of the year over the southeast.
```{r}
library(USAboundaries)

mp <- us_counties(states = c("FL", "GA", "AL", "SC")) %>%
  st_cast("MULTILINESTRING") %>%
  st_crop(xmin = -89, xmax = -80, ymin = 29, ymax = 33) 

tmaxSE <- tmaxDailyAvg %>%
  crop(mp)

library(tmap)

tm_shape(tmaxSE[[1:6]]) +
  tm_raster() +
tm_shape(mp) +
  tm_lines(col = "gray70")
```

## Smooth the temperature variability

We extract a pixel from our dataset at coordinates -89ยบ of longitude and 31ยบ of latitude using the `extract()` function. The result is a matrix with a single row corresponding to the pixel and 366 columns of the days of the year. Then we create a data frame with a dummy date and the extracted maximum temperature.
```{r}
point_ts <- raster::extract(tmaxDailyAvg, 
                            matrix(c(-89, 31), nrow = 1))
dim(point_ts)
```
```{r}
df <- data.frame(date = seq(as_date("2000-01-01"), as_date("2000-12-31"), "day"),
                 tmax = point_ts[1, ])
```

Visualize the average high temperatures by day of year.
```{r}
ggplot(data = df, 
       mapping = aes(date, tmax)) + 
  geom_line() + 
  scale_x_date(date_breaks = "month", date_labels = "%b") +
  scale_y_continuous(breaks = seq(10, 36, 2)) +
  labs(y = "maximum temperature", x = "", colour =  "") +
  theme_minimal()
```

Create and apply a function to smooth.
```{r}
daily_smooth <- function(x, f = 1/32){
  
  if(all(is.na(x))){
   
    return(x) 
   
  } else {
  y <- c(x, x, x)
  x.mid <- 1:366
  offset <- 366
  y.smooth <- lowess(y, f = f)
  est <- y.smooth$y[x.mid + offset]

  return(est)
  
  }
}

df$tmaxS <- daily_smooth(df$tmax)
```

Plot together
```{r}
dfL <- df %>% 
       pivot_longer(c(2, 4), 
                    names_to = "var", 
                    values_to = "temp")

ggplot(dfL, 
       aes(date, temp, 
           colour = var)) + 
     geom_line() + 
  scale_x_date(date_breaks = "month", date_labels = "%b") +
  scale_y_continuous(breaks = seq(10, 36, 2)) +
  scale_colour_manual(values = c("orange", "red", "black")) +
  labs(y = "maximum temperature", x = "", colour =  "") +
  theme_minimal()
```

As we see in the graph, the smoothed curve follows the original curve very well. 

In the next step we apply our function to the raster brick with the `calc()` function. The function returns as many layers as those returned by the function used for each of the time series.

About 3 minutes.
```{r}
t0 <- proc.time()
tmaxDailyAvgSmooth <- calc(tmaxDailyAvg, 
                           fun = daily_smooth)
proc.time() - t0
```

## Visualization

To visualize the maximum temperatures throughout the year, first we convert the raster brick to a data frame, including longitude and latitude and removing all time series with missing values (`NA`).
```{r}
t0 <- proc.time()
df <- as.data.frame(rasterToPoints(tmaxDailyAvgSmooth))
df <- set_names(df, 
                nm = c("lon", "lat", str_c("D", 1:366)))
head(df[, 1:10])
proc.time() - t0
```

Second, we import the administrative boundaries with the `ne_countries()` function from the {rnaturalearth} package, limiting the extension to the region of the Iberian Peninsula, southern France and northern Africa.

```{r}
mp <- us_states() %>%
  st_cast("MULTILINESTRING") %>%
  st_crop(xmin = -125, xmax = -66, ymin = 24, ymax = 50)
```

Third, we create a vector with the day of the year as labels in order to include them later in the animation. In addition, we define the break points for the maximum temperature, adapted to the distribution of our data, to obtain a categorization with a total of 20 classes.
```{r}
lab <- as_date(0:365, origin = "2000-01-01") %>% 
  format("%d %B")
```

Fourth, we apply the `cut()` function with the breaks to all the columns with temperature data of each day of the year.
```{r}
ct <- seq(-20, 48, by = 4)
dfc <- df %>%
  mutate_at(3:368, cut, breaks = ct)
```

Fifth we define the color ramp.
```{r}
col_spec <- colorRampPalette(rev(brewer.pal(11, "RdBu")))
```

### Static map

Here we make a map of May 15 (day 136). We use the `aes_string()` function instead of `aes()` to use the column names in string format. With the `geom_raster()` function we add the gridded temperature data as the first layer of the graph and with `geom_sf()` the boundaries in {sf} class. Finally, the `guide_colorsteps()` function allows us to create a nice legend based on the classes created by the `cut()` function.
```{r}
ggplot(dfc) + 
  geom_raster(aes_string("lon", "lat", fill = "D136")) +
  geom_sf(data = mp,
          colour = "grey70", size = 0.2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(17), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = .5,
                                 title.position = "right",
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = "top",
      legend.justification = 1,
      plot.caption = element_text(margin = margin(b = 5, t = 10, unit = "pt")),                
      plot.title = element_text(size = 16, face = "bold", 
                                margin = margin(b = 2, t = 5, unit = "pt")),
     plot.subtitle = element_text(size = 13, 
                                  margin = margin(b = 10, t = 5, unit = "pt"))) +
   labs(title = "Average daily high temperature", 
     subtitle = lab[136], 
     caption = "Reference period 1990-1993. Data: PRISM",
     fill = "ยบC")
```

### Animation

We use a loop over the columns and join all the created images with the {gifski} package.

Before looping we create a vector with the time steps or names of the columns, and another vector with the name of the images, including the name of the folder. In order to obtain a list of images ordered by their number, we must maintain three figures, filling the positions on the left with zeros.
```{r}
time_step <- str_c("D", 1:366)
files <- str_c("us_tmax/D", str_pad(1:366, 3, "left", "0"), ".png")
```
Lastly, we include the above plot construction in a for loop. This takes a few minutes to run.
```{r}
for(i in 1:366){

 ggplot(dfc) + 
         geom_raster(aes_string("lon", "lat", fill = time_step[i])) +
         geom_sf(data = mp,
                 colour = "grey70", size = .2) +
  coord_sf(expand = FALSE) +
  scale_fill_manual(values = col_spec(20), drop = FALSE) +
  guides(fill = guide_colorsteps(barwidth = 30, 
                                 barheight = .5,
                                 title.position = "right",
                                 title.vjust = .1)) +
   theme_void() +
   theme(legend.position = "top",
         legend.justification = 1,
         plot.caption = element_text(margin = margin(b = 5, t = 10, unit = "pt")),
         plot.title = element_text(size = 16, face = "bold", 
                                margin = margin(b = 2, t = 5, unit = "pt")),
         plot.subtitle = element_text(size = 13, 
                                  margin = margin(b = 10, t = 5, unit = "pt"))) +
   labs(title = "Average high temperature during the year", 
     subtitle = lab[i], 
     caption = "Reference period 1990-1993. Data: PRISM",
     fill = "ยบC")

  ggsave(files[i], width = 8.28, height = 7.33, type = "cairo")
  
}
```

After having created images for each day of the year, we only have to create the gif.
```{r}
gifski(files, "us_tmax.gif", 
       width = 800, height = 700, 
       loop = FALSE, 
       delay = 0.05)
```


Spatial autocorrelation range.
```{r}
library(blockCV)

sac <- spatialAutoRange(rasterLayer = tmax.b,
                        sampleNumber = 5000,
                        doParallel = TRUE,
                        plotVariograms = TRUE,
                        showPlots = TRUE)

sac$variograms$var_model

tmax.rp <- projectRaster(tmax.r, crs = "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")

sac <- spatialAutoRange(rasterLayer = tmax.rp,
                        sampleNumber = 5000,
                        doParallel = TRUE,
                        showPlots = TRUE)
sac$variograms$var_model
```

If the domain is to large, clear calm nights will result in a trend that will overwhelm the local spatial autocorrelation.

# Ian's locations

Packages
```{r}
library(dplyr)
library(tmap)
library(sf)
library(lubridate)
library(rnaturalearth)
```

Get data from Ian's private location tracking server for June 15, 2019. Changed to hosted file to hide API key.
```{r}
L <- "https://www.dropbox.com/s/zx0w39gedhcjsib/2019-06-15.json?dl=1"
df <- jsonlite::fromJSON(L, flatten = TRUE) %>%
  as.data.frame()
```

Get the time stamp as a time object.
```{r}
Time <- as_datetime(df$locations.properties.timestamp)
```

Get the spatial coordinates, speed, and convert to a simple feature data frame.
```{r}
Space <- matrix(unlist(df$locations.geometry.coordinates), 
                ncol = 2, 
                byrow = TRUE) %>%
         data.frame()
Speed <- df$locations.properties.speed
Acc <- df$locations.properties.horizontal_accuracy

SpaceTime <- data.frame(lon = Space$X1, 
                        lat = Space$X2, 
                        Time,
                        Hour = hour(Time),
                        Speed,
                        Acc)

df_sf <- st_as_sf(SpaceTime, coords = c("lon", "lat"), 
                  crs = 4326)
```

Make a static map using **tmap**.
```{r}
tmap_mode("view")

tm_shape(df_sf) +
  tm_dots(col = "Acc")

tmap_mode("plot")
```

Make a map using Leaflet, using custom markers.
```{r}
library(leaflet)
m <- leaflet() %>%
  addCircleMarkers(data = df_sf) %>%
 addProviderTiles(providers$CartoDB.Positron)
m  # Print the map
```

Center ggmap near Ian's house.
```{r}
library(ggmap)

register_google(key = "AIzaSyA7buW39is2slTxrL_Y6wXbkGuPv63RALw")
homework <- get_map(location = c(-71.13, 42.38), maptype = "terrain", source = "google", zoom = 10, API_console_key = "AIzaSyA7buW39is2slTxrL_Y6wXbkGuPv63RALw")
ggmap(homework)
```

See path of Ian's location throughout the day. 
```{r}
ggmap(homework) + geom_path(data = SpaceTime, size = 1)
```

Animate dot of Ian's location throughout the day using gganimate. Some points are outside the range of this map.
```{r}
library(ggploty)
library(ggplot2)
library(gganimate)
library(gifski)
p <- ggmap(homework) + 
  geom_point(data = SpaceTime, size = 1) + 
  transition_time(SpaceTime$Time)
animate(p,nframes = 50, fps = 20) #render
```

Linearly map Ian's location by minute. This creates a dataframe of 1440 entries, one for every minute of the day.
```{r}
aim <- seq(as.POSIXct('2019-06-15 00:00:00'), as.POSIXct('2019-06-15 23:59:59'), by = "mins")
length(aim)
xa <- approx(as.POSIXct(SpaceTime$Time), method="linear", rule=2, SpaceTime$lat, xout=aim)$y
ya <- approx(as.POSIXct(SpaceTime$Time), method="linear", rule=2, SpaceTime$lon, xout=aim)$y

idfi <- as.data.frame(aim)
idfi["lat"] <- xa
idfi["lon"] <- ya
```

Play Ian's minute-by-minute location with a wake effect.
```{r}
p <- ggmap(homework) + 
  geom_point(color="red", fill="grey", data = idfi, size = 4) + 
  transition_time(idfi$aim) + 
  labs(title = "Ian's Location",subtitle = "Time:{frame}", x = "Long", y = "Lat") + 
  shadow_wake(wake_length = 0.10, size=0.5, falloff ="cubic-in", alpha = TRUE, fill="blue") 
p
```

Set the "camera" to follow Ian's location through the day. gganimate takes a list of xmin, xmax, ymin, and ymax values via view_zoom_manual to define the frame. Let's do one frame for each hour. Please let me know if you would do this differently.
```{r}
# Set the bounding boxes such that they are larger than the location point. Important when Ian spends more than an hour in one place. 
idfi <- idfi %>% 
  mutate(xmin = lon - 0.5)
idfi <- idfi  %>% 
  mutate(xmax = lon + 0.5)
idfi <- idfi  %>% 
  mutate(ymin = lat - 0.5)
idfi <- idfi  %>% 
  mutate(ymax = lat + 0.5)

# Find the mean of the bounding box every hour.
xmin <- colMeans(matrix(idfi$xmin, nrow=60))
ymin <- colMeans(matrix(idfi$ymin, nrow=60))
xmax <- colMeans(matrix(idfi$xmax, nrow=60))
ymax <- colMeans(matrix(idfi$ymax, nrow=60))

newResult <- list(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax)

zoom <- get_map(location = c( -71.13, 42.38), maptype = "toner", source = "stamen", zoom = 12, force = TRUE)
world<- get_map(location = c( -71.5, 42.38), maptype = "toner", source = "stamen", zoom = 8, force = TRUE)

p <- ggmap(world, API_console_key = "AIzaSyA7buW39is2slTxrL_Y6wXbkGuPv63RALw") +  
  inset_ggmap(zoom) + 
  geom_point(color="red", fill="grey", data = idfi,aes(y = idfi$lat, x= idfi$lon), size = 4) + 
  transition_time(idfi$aim) + 
  view_zoom_manual(1, 1, xmin = newResult$xmin, xmax = newResult$xmax, ymin = newResult$ymin, ymax = newResult$ymax, wrap = TRUE)
p
```

Bulk download all daily tmax for 1991 from ftp site: ftp://prism.nacse.org/daily/tmax/1991/

Use the curl library to extract the directory listing
```{r, eval=FALSE}
library(curl)
url <- "ftp://prism.nacse.org/daily/tmax/1991/"
h <- new_handle(dirlistonly = TRUE)
con <- curl(url, "r", h)
tbl <- read.table(con, stringsAsFactors = TRUE, fill = TRUE)
close(con)
head(tbl)
```

Paste the relevant ones on to the url and use
```{r, eval=FALSE}
urls <- paste0(url, tbl[1:5,1])
fls <- basename(urls)
curl_fetch_disk(urls[1], fls[1])
```
